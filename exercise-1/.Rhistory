# load relevant libraries
library(httr)
library(jsonlite)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
movie.name <- "Ready Player One"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
base_url <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nty_apikey, query = movie.name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_url, resource), query = query_params)
body <- content(response, "text")
data <- fromJSON(body)
# What kind of data structure did this produce? A data frame? A list?
typeof(data)
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
View(data)
names(data$results)
# Flatten the movie reviews content into a data structure called `reviews`
reviews <- flatten(data$results)
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
most_recent <- reviews[1, ]
headline <- most_recent$headline
short_summary <- most_recent$summary_short
full_article <- most_recent$link.url
# Create a list of the three pieces of information from above.
# Print out the list.
information <- list(headline, short_summary, full_article)
print(information)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
movie.name <- "Ready Player One"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
base_url <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nty_apikey, query = movie.name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_url, resource), query = query_params)
body <- content(response, "text")
data <- fromJSON(body)
# What kind of data structure did this produce? A data frame? A list?
typeof(data)
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
View(data)
names(data$results)
```{r setup, include=FALSE, source(exercise.R)}
```{r setup, include=FALSE, source = source(exercise.R)}
setwd("~/git/ch12-r-markdown/exercise-1")
```{r setup, include=FALSE, source(exercise.R)}
```{r setup, include=FALSE, source("exercise.R"")}
source("exercise.R")
source("exercise.R")
library(rmarkdown)
source("exercise.R")
knitr::opts_chunk$set(echo = TRUE)
source("exercise.R")
library(knitr)
source("exercise.R")
install.packages('ggplot2', dependencies = TRUE)
library(ggplot2)
install.packages("XQuartz")
---
title: "Movie Review"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("exercise.R"")
```
## R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r cars}
summary(cars)
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
install.packages("xQuartz")
install.packages(xQuartz)
library(XQuartz)
install.packages(XQuartz)
install.packages("XQuartz")
setwd("~/git/ch11-apis/exercise-2")
setwd("~/git/ch12-r-markdown/exercise-1")
setwd("~/git/ch12-r-markdown/exercise-1")
knitr::opts_chunk$set(echo = TRUE)
source("exercise.R")
# load relevant libraries
library(httr)
library(jsonlite)
# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
source("apikey.R")
# Create a variable `movie.name` that is the name of a movie of your choice.
movie.name <- "Ready Player One"
# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie.name` variable as the search query!
base_url <- "https://api.nytimes.com/svc/movies/v2"
resource <- "/reviews/search.json"
query_params <- list("api-key" = nty_apikey, query = movie.name)
# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
response <- GET(paste0(base_url, resource), query = query_params)
body <- content(response, "text")
data <- fromJSON(body)
# What kind of data structure did this produce? A data frame? A list?
typeof(data)
# Manually inspect the returned data and identify the content of interest
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
View(data)
names(data$results)
# Flatten the movie reviews content into a data structure called `reviews`
reviews <- flatten(data$results)
# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
most_recent <- reviews[1, ]
headline <- most_recent$headline
short_summary <- most_recent$summary_short
full_article <- most_recent$link.url
# Create a list of the three pieces of information from above.
# Print out the list.
information <- list(headline, short_summary, full_article)
print(information)
